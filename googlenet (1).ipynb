{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %matplotlib inline is not required in scripts or Kaggle notebooks anymore\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport seaborn as sns\nfrom PIL import Image\n\n# Seed for reproducibility\nnp.random.seed(123)\n\n# Sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import confusion_matrix\n\n# TensorFlow/Keras (use this version only for consistency)\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    Dense, Activation, Dropout, Flatten,\n    Conv2D, MaxPooling2D, BatchNormalization\n)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras import backend as K\n\n#%% Load metadata\nbase_skin_dir = '/kaggle/input/skin-cancer-mnist-ham10000'\n\n# Map image ids to paths\nimageid_path_dict = {\n    os.path.splitext(os.path.basename(x))[0]: x\n    for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))\n}\n\n# Map lesion codes to full names\nlesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}\n\n# Read metadata CSV\nskin_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n\n# Add image paths and mapped lesion names\nskin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)\nskin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get)\n\n# Encode class labels as integers\nskin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes\n\n# Fill missing age values with the mean\nskin_df['age'].fillna((skin_df['age'].mean()), inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T10:57:11.766936Z","iopub.execute_input":"2025-05-13T10:57:11.767428Z","iopub.status.idle":"2025-05-13T10:57:12.071051Z","shell.execute_reply.started":"2025-05-13T10:57:11.767402Z","shell.execute_reply":"2025-05-13T10:57:12.070297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skin_df = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\n\nskin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)\nskin_df['cell_type'] = skin_df['dx'].map(lesion_type_dict.get)\nskin_df['cell_type_idx'] = pd.Categorical(skin_df['cell_type']).codes\nskin_df['age'].fillna((skin_df['age'].mean()), inplace=True)\n\n#%% Resize images\nskin_df['image'] = skin_df['path'].map(lambda x: np.asarray(Image.open(x).resize((75,75))))\n\n#%% Prepare data\nfeatures = skin_df.drop(columns=['cell_type_idx'], axis=1)\ntarget = skin_df['cell_type_idx']\n\nx_train_o, x_test_o, y_train_o, y_test_o = train_test_split(features, target, test_size=0.20, random_state=1234)\nx_train = np.asarray(x_train_o['image'].tolist())\nx_test = np.asarray(x_test_o['image'].tolist())\n\n# Normalize\nx_train_mean = np.mean(x_train)\nx_train_std = np.std(x_train)\nx_test_mean = np.mean(x_test)\nx_test_std = np.std(x_test)\n\nx_train = (x_train - x_train_mean) / x_train_std\nx_test = (x_test - x_test_mean) / x_test_std\n\n# One-hot encode\ny_train = to_categorical(y_train_o, num_classes=7)\ny_test = to_categorical(y_test_o, num_classes=7)\n\n# Validation split\nx_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.1, random_state=2)\n\n# Reshape\nx_train = x_train.reshape(-1, 75, 75, 3)\nx_test = x_test.reshape(-1, 75, 75, 3)\nx_validate = x_validate.reshape(-1, 75, 75, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T10:57:53.558894Z","iopub.execute_input":"2025-05-13T10:57:53.559558Z","iopub.status.idle":"2025-05-13T11:00:15.283851Z","shell.execute_reply.started":"2025-05-13T10:57:53.559532Z","shell.execute_reply":"2025-05-13T11:00:15.283071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.callbacks import EarlyStopping\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:41:40.522491Z","iopub.execute_input":"2025-05-13T11:41:40.522779Z","iopub.status.idle":"2025-05-13T11:41:40.527471Z","shell.execute_reply.started":"2025-05-13T11:41:40.522759Z","shell.execute_reply":"2025-05-13T11:41:40.526924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inception_module(x, filters):\n    conv1 = Conv2D(filters[0], (1, 1), padding='same', activation='relu')(x)\n\n    conv3 = Conv2D(filters[1], (1, 1), padding='same', activation='relu')(x)\n    conv3 = Conv2D(filters[2], (3, 3), padding='same', activation='relu')(conv3)\n\n    conv5 = Conv2D(filters[3], (1, 1), padding='same', activation='relu')(x)\n    conv5 = Conv2D(filters[4], (5, 5), padding='same', activation='relu')(conv5)\n\n    pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n    pool = Conv2D(filters[5], (1, 1), padding='same', activation='relu')(pool)\n\n    output = concatenate([conv1, conv3, conv5, pool], axis=3)\n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:41:43.503803Z","iopub.execute_input":"2025-05-13T11:41:43.504059Z","iopub.status.idle":"2025-05-13T11:41:43.509567Z","shell.execute_reply.started":"2025-05-13T11:41:43.50404Z","shell.execute_reply":"2025-05-13T11:41:43.50884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_googlenet(input_shape=(75, 75, 3), num_classes=7):\n    input_layer = Input(shape=input_shape)\n\n    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n    x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)\n    x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\n    x = inception_module(x, [64, 96, 128, 16, 32, 32])\n    x = inception_module(x, [128, 128, 192, 32, 96, 64])\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\n    x = inception_module(x, [192, 96, 208, 16, 48, 64])\n    x = inception_module(x, [160, 112, 224, 24, 64, 64])\n    x = inception_module(x, [128, 128, 256, 24, 64, 64])\n    x = inception_module(x, [112, 144, 288, 32, 64, 64])\n    x = inception_module(x, [256, 160, 320, 32, 128, 128])\n    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\n    x = inception_module(x, [256, 160, 320, 32, 128, 128])\n    x = inception_module(x, [384, 192, 384, 48, 128, 128])\n\n    x = AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid')(x)\n    x = Dropout(0.4)(x)\n    x = Flatten()(x)\n    x = Dense(num_classes, activation='softmax')(x)\n\n    model = Model(inputs=input_layer, outputs=x)\n    return model\nmodel = build_googlenet(input_shape=(75, 75, 3), num_classes=7)\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:41:46.734495Z","iopub.execute_input":"2025-05-13T11:41:46.735174Z","iopub.status.idle":"2025-05-13T11:41:47.375704Z","shell.execute_reply.started":"2025-05-13T11:41:46.73515Z","shell.execute_reply":"2025-05-13T11:41:47.375021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n#%% Data Augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range=0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=False,\n    vertical_flip=False\n)\ndatagen.fit(x_train)\n\n#%% Callbacks\nlr_reduce = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=1e-5)\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:41:52.787768Z","iopub.execute_input":"2025-05-13T11:41:52.788274Z","iopub.status.idle":"2025-05-13T11:41:53.143354Z","shell.execute_reply.started":"2025-05-13T11:41:52.78825Z","shell.execute_reply":"2025-05-13T11:41:53.142768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%% Training\nhistory = model.fit(\n    datagen.flow(x_train, y_train, batch_size=64),\n    epochs=10,\n    validation_data=(x_validate, y_validate),\n    steps_per_epoch=len(x_train) // 64,\n    callbacks=[lr_reduce, early_stop],\n    verbose=1\n)\n\n#%% Evaluation\nloss_test, acc_test = model.evaluate(x_test, y_test, verbose=1)\nloss_val, acc_val = model.evaluate(x_validate, y_validate, verbose=1)\nprint(f\"Validation Accuracy: {acc_val:.4f}, Validation Loss: {loss_val:.4f}\")\nprint(f\"Test Accuracy: {acc_test:.4f}, Test Loss: {loss_test:.4f}\")\n\n#%% Save\nmodel.save(\"GoogLeNet_HAM10000.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:42:07.020838Z","iopub.execute_input":"2025-05-13T11:42:07.021111Z","iopub.status.idle":"2025-05-13T11:44:12.118283Z","shell.execute_reply.started":"2025-05-13T11:42:07.021091Z","shell.execute_reply":"2025-05-13T11:44:12.11768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_model_history(model_history):\n    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n    # Accuracy\n    axs[0].plot(model_history.history['accuracy'], label='Train Accuracy')\n    axs[0].plot(model_history.history['val_accuracy'], label='Validation Accuracy')\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].legend()\n    # Loss\n    axs[1].plot(model_history.history['loss'], label='Train Loss')\n    axs[1].plot(model_history.history['val_loss'], label='Validation Loss')\n    axs[1].set_title('Model Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_ylabel('Loss')\n    axs[1].legend()\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:44:23.354485Z","iopub.execute_input":"2025-05-13T11:44:23.354983Z","iopub.status.idle":"2025-05-13T11:44:23.360225Z","shell.execute_reply.started":"2025-05-13T11:44:23.35496Z","shell.execute_reply":"2025-05-13T11:44:23.359558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_model_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:45:09.998421Z","iopub.execute_input":"2025-05-13T11:45:09.998678Z","iopub.status.idle":"2025-05-13T11:45:10.360721Z","shell.execute_reply.started":"2025-05-13T11:45:09.998658Z","shell.execute_reply":"2025-05-13T11:45:10.360064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Plot confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion Matrix',\n                          cmap=plt.cm.Blues):\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    \n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], '.2f') if normalize else int(cm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:46:05.110987Z","iopub.execute_input":"2025-05-13T11:46:05.111253Z","iopub.status.idle":"2025-05-13T11:46:05.118178Z","shell.execute_reply.started":"2025-05-13T11:46:05.111237Z","shell.execute_reply":"2025-05-13T11:46:05.117416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = list(lesion_type_dict.values())  # Class names in order of appearance\n\ndef plot_confusion_matrix(cm, classes):\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.title('Confusion Matrix')\n    plt.show()\n\nplot_confusion_matrix(cm, classes=labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T11:51:45.22713Z","iopub.execute_input":"2025-05-13T11:51:45.227425Z","iopub.status.idle":"2025-05-13T11:51:45.526895Z","shell.execute_reply.started":"2025-05-13T11:51:45.227405Z","shell.execute_reply":"2025-05-13T11:51:45.526247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}